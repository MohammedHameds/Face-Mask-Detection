{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Input,AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 20\n",
    "batchs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "path = r\"dataset\"\n",
    "for category in os.listdir(path) :\n",
    "    folder_path = os.path.join(path,category)\n",
    "    for img in os.listdir(folder_path) :\n",
    "        img_path = os.path.join(folder_path,img)\n",
    "        img = load_img(img_path,target_size = (224,224))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_preprocess = preprocess_input(img_arr)\n",
    "        data.append(img_preprocess)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "                                    test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=learning_rate, decay=learning_rate / epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.3828 - accuracy: 0.8622 - val_loss: 0.1400 - val_accuracy: 0.9857\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.1502 - accuracy: 0.9624 - val_loss: 0.0756 - val_accuracy: 0.9883\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 151s 2s/step - loss: 0.1053 - accuracy: 0.9736 - val_loss: 0.0566 - val_accuracy: 0.9896\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 158s 2s/step - loss: 0.0824 - accuracy: 0.9786 - val_loss: 0.0484 - val_accuracy: 0.9909\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.0700 - accuracy: 0.9806 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 147s 2s/step - loss: 0.0572 - accuracy: 0.9868 - val_loss: 0.0417 - val_accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 151s 2s/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0361 - val_accuracy: 0.9922\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 151s 2s/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.0349 - val_accuracy: 0.9922\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0358 - val_accuracy: 0.9909\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 159s 2s/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 0.0383 - val_accuracy: 0.9909\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 122s 1s/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.0311 - val_accuracy: 0.9922\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 122s 1s/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.0364 - val_accuracy: 0.9909\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 132s 1s/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0362 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0300 - val_accuracy: 0.9922\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.0294 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 136s 1s/step - loss: 0.0337 - accuracy: 0.9904 - val_loss: 0.0347 - val_accuracy: 0.9909\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 133s 1s/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0291 - val_accuracy: 0.9935\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 128s 1s/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0304 - val_accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 129s 1s/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.0304 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204ab50f940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=batchs),\n",
    "    steps_per_epoch=len(trainX) // batchs,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // batchs,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 22s 827ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testX, batch_size=batchs)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(testY.argmax(axis=1), predictions,\n",
    "                            target_names=lb.classes_)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/mask_detector_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
